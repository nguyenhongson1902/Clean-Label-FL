2023-06-26 23:32:30.693 | DEBUG    | federated_learning.arguments:log:221 - Arguments: 
Batch Size: 64
Test Batch Size: 100
Epochs: 1000
Learning Rate: 0.01
Momentum: 0.5
CUDA Enabled: True
Log Interval: 100
Scheduler Step Size: 50
Scheduler Gamma: 0.5
Scheduler Minimum Learning Rate: 1e-10
Client Selection Strategy: None
Client Selection Strategy Arguments: null
Model Saving Enabled: False
Model Saving Interval: 1
Model Saving Path (Relative): models
Epoch Save Start Prefix: start
Epoch Save End Suffix: end
Number of Clients: 5
Number of Poisoned Clients: 1
NN: <function ResNet18_201 at 0x7fb397ec3490>
Train Data Loader Path: data_loaders/cifar10/train_data_loader.pickle
Test Data Loader Path: data_loaders/cifar10/test_data_loader.pickle
Loss Function: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
Default Model Folder Path: default_models
Data Path: data

INFO flwr 2023-06-26 23:32:31,428 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)
DEBUG flwr 2023-06-26 23:32:31,429 | connection.py:39 | ChannelConnectivity.IDLE
DEBUG flwr 2023-06-26 23:32:31,429 | connection.py:39 | ChannelConnectivity.CONNECTING
DEBUG flwr 2023-06-26 23:32:31,429 | connection.py:39 | ChannelConnectivity.READY
Poisoned workers:  [0]
Number of target samples:  [100]
params_dict
state_dict
Client index: 0
  0%|          | 0/1000 [00:00<?, ?it/s]2023-06-26 23:32:43.748 | INFO     | __main__:train_poisoned_worker:606 - Training epoch #0 on poisoned client #0
2023-06-26 23:32:43.749 | INFO     | __main__:train:211 - Client 0 is poisoned
./checkpoint/best_noise__client_0__target_label_2__exp_83.npy loaded
len(ori_train) 10000
random_poison_idx [2, 9, 10, 17, 19]
Traing dataset size is: 10000  Poison numbers is: 5

  0%|          | 0/100 [00:00<?, ?it/s][A
Acc 9.00 Loss: 2.50:   0%|          | 0/100 [00:06<?, ?it/s][A
Acc 9.00 Loss: 2.50:   1%|          | 1/100 [00:06<11:15,  6.82s/it][A
Acc 9.00 Loss: 2.50:   1%|          | 1/100 [00:06<11:15,  6.82s/it][A
Acc 12.00 Loss: 2.43:   1%|          | 1/100 [00:06<11:15,  6.82s/it][A
Acc 12.00 Loss: 2.43:   3%|â–Ž         | 3/100 [00:06<02:57,  1.83s/it][A
Acc 13.25 Loss: 2.39:   3%|â–Ž         | 3/100 [00:07<02:57,  1.83s/it][A
Acc 14.00 Loss: 2.36:   3%|â–Ž         | 3/100 [00:07<02:57,  1.83s/it][A
Acc 14.00 Loss: 2.36:   5%|â–Œ         | 5/100 [00:07<01:28,  1.07it/s][A
Acc 14.67 Loss: 2.34:   5%|â–Œ         | 5/100 [00:07<01:28,  1.07it/s][A
Acc 15.14 Loss: 2.32:   5%|â–Œ         | 5/100 [00:07<01:28,  1.07it/s][A
Acc 15.14 Loss: 2.32:   7%|â–‹         | 7/100 [00:07<00:53,  1.74it/s][A
Acc 15.75 Loss: 2.30:   7%|â–‹         | 7/100 [00:07<00:53,  1.74it/s][A
Acc 16.56 Loss: 2.29:   7%|â–‹         | 7/100 [00:07<00:53,  1.74it/s][A
Acc 16.56 Loss: 2.29:   9%|â–‰         | 9/100 [00:07<00:35,  2.56it/s][A
Acc 17.30 Loss: 2.28:   9%|â–‰         | 9/100 [00:07<00:35,  2.56it/s][A
Acc 17.18 Loss: 2.27:   9%|â–‰         | 9/100 [00:07<00:35,  2.56it/s][A
Acc 17.18 Loss: 2.27:  11%|â–ˆ         | 11/100 [00:07<00:25,  3.55it/s][A
Acc 17.67 Loss: 2.26:  11%|â–ˆ         | 11/100 [00:07<00:25,  3.55it/s][A
Acc 18.00 Loss: 2.25:  11%|â–ˆ         | 11/100 [00:07<00:25,  3.55it/s][A
Acc 18.00 Loss: 2.25:  13%|â–ˆâ–Ž        | 13/100 [00:07<00:18,  4.61it/s][A
Acc 17.86 Loss: 2.24:  13%|â–ˆâ–Ž        | 13/100 [00:07<00:18,  4.61it/s][A
Acc 17.73 Loss: 2.23:  13%|â–ˆâ–Ž        | 13/100 [00:08<00:18,  4.61it/s][A
Acc 17.73 Loss: 2.23:  15%|â–ˆâ–Œ        | 15/100 [00:08<00:14,  5.69it/s][A
Acc 18.00 Loss: 2.23:  15%|â–ˆâ–Œ        | 15/100 [00:08<00:14,  5.69it/s][A
Acc 18.29 Loss: 2.22:  15%|â–ˆâ–Œ        | 15/100 [00:08<00:14,  5.69it/s][A
Acc 18.29 Loss: 2.22:  17%|â–ˆâ–‹        | 17/100 [00:08<00:12,  6.73it/s][A
Acc 18.67 Loss: 2.21:  17%|â–ˆâ–‹        | 17/100 [00:08<00:12,  6.73it/s][A
Acc 18.95 Loss: 2.20:  17%|â–ˆâ–‹        | 17/100 [00:08<00:12,  6.73it/s][A
Acc 18.95 Loss: 2.20:  19%|â–ˆâ–‰        | 19/100 [00:08<00:10,  7.74it/s][A
Acc 19.15 Loss: 2.19:  19%|â–ˆâ–‰        | 19/100 [00:08<00:10,  7.74it/s][A
Acc 19.62 Loss: 2.18:  19%|â–ˆâ–‰        | 19/100 [00:08<00:10,  7.74it/s][A
Acc 19.62 Loss: 2.18:  21%|â–ˆâ–ˆ        | 21/100 [00:08<00:09,  8.78it/s][A
Acc 19.59 Loss: 2.17:  21%|â–ˆâ–ˆ        | 21/100 [00:08<00:09,  8.78it/s][A
Acc 19.70 Loss: 2.17:  21%|â–ˆâ–ˆ        | 21/100 [00:08<00:09,  8.78it/s][A
Acc 19.70 Loss: 2.17:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:08<00:08,  9.51it/s][A
Acc 19.79 Loss: 2.16:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:08<00:08,  9.51it/s][A
Acc 19.96 Loss: 2.16:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:08<00:08,  9.51it/s][A
Acc 19.96 Loss: 2.16:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:08<00:07, 10.02it/s][A
Acc 20.46 Loss: 2.15:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:08<00:07, 10.02it/s][A
Acc 20.63 Loss: 2.14:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:09<00:07, 10.02it/s][A
Acc 20.63 Loss: 2.14:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:09<00:07, 10.40it/s][A
Acc 21.04 Loss: 2.13:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:09<00:07, 10.40it/s][A
Acc 21.17 Loss: 2.12:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:09<00:07, 10.40it/s][A
Acc 21.17 Loss: 2.12:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:09<00:06, 10.70it/s][A
Acc 21.50 Loss: 2.12:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:09<00:06, 10.70it/s][A
Acc 21.81 Loss: 2.11:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:09<00:06, 10.70it/s][A
Acc 21.81 Loss: 2.11:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:09<00:06, 10.92it/s][A
Acc 22.06 Loss: 2.10:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:09<00:06, 10.92it/s][A
Acc 22.45 Loss: 2.09:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:09<00:06, 10.92it/s][A
Acc 22.45 Loss: 2.09:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:09<00:06, 11.05it/s][A
Acc 22.74 Loss: 2.08:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:09<00:06, 11.05it/s][A
Acc 22.71 Loss: 2.08:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:09<00:06, 11.05it/s][A
Acc 22.71 Loss: 2.08:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:09<00:05, 11.14it/s][A
Acc 22.86 Loss: 2.08:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:09<00:05, 11.14it/s][A
Acc 23.00 Loss: 2.07:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:09<00:05, 11.14it/s][A
Acc 23.00 Loss: 2.07:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:09<00:05, 11.24it/s][A
Acc 23.05 Loss: 2.07:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:10<00:05, 11.24it/s][A
Acc 23.44 Loss: 2.06:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:10<00:05, 11.24it/s][A
Acc 23.44 Loss: 2.06:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:10<00:05, 11.29it/s][A
Acc 23.92 Loss: 2.06:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:10<00:05, 11.29it/s][A
Acc 24.05 Loss: 2.05:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:10<00:05, 11.29it/s][A
Acc 24.05 Loss: 2.05:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:10<00:05, 11.18it/s][A
Acc 24.12 Loss: 2.05:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:10<00:05, 11.18it/s][A
Acc 24.37 Loss: 2.05:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:10<00:05, 11.18it/s][A
Acc 24.37 Loss: 2.05:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:10<00:05, 11.16it/s][A
Acc 24.66 Loss: 2.04:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:10<00:05, 11.16it/s][A
Acc 24.64 Loss: 2.04:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:10<00:05, 11.16it/s][A
Acc 24.64 Loss: 2.04:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:04, 11.24it/s][A
Acc 24.76 Loss: 2.03:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:04, 11.24it/s][A
Acc 25.00 Loss: 2.03:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:04, 11.24it/s][A
Acc 25.00 Loss: 2.03:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:04, 11.30it/s][A
Acc 25.15 Loss: 2.02:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:04, 11.30it/s][A
Acc 25.41 Loss: 2.02:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:04, 11.30it/s][A
Acc 25.41 Loss: 2.02:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:10<00:04, 11.69it/s][A
Acc 25.52 Loss: 2.01:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:11<00:04, 11.69it/s][A
Acc 25.67 Loss: 2.01:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:11<00:04, 11.69it/s][A
Acc 25.67 Loss: 2.01:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:11<00:04, 11.61it/s][A
Acc 25.71 Loss: 2.00:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:11<00:04, 11.61it/s][A
Acc 25.98 Loss: 2.00:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:11<00:04, 11.61it/s][A
Acc 25.98 Loss: 2.00:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:11<00:03, 11.77it/s][A
Acc 26.19 Loss: 1.99:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:11<00:03, 11.77it/s][A
Acc 26.27 Loss: 1.99:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:11<00:03, 11.77it/s][A
Acc 26.27 Loss: 1.99:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:11<00:03, 11.68it/s][A
Acc 26.34 Loss: 1.99:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:11<00:03, 11.68it/s][A
Acc 26.58 Loss: 1.98:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:11<00:03, 11.68it/s][A
Acc 26.58 Loss: 1.98:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:11<00:03, 11.77it/s][A
Acc 26.64 Loss: 1.98:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:11<00:03, 11.77it/s][A
Acc 26.66 Loss: 1.97:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:11<00:03, 11.77it/s][A
Acc 26.66 Loss: 1.97:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:11<00:03, 11.63it/s][A
Acc 26.63 Loss: 1.97:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:11<00:03, 11.63it/s][A
Acc 26.77 Loss: 1.97:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:11<00:03, 11.63it/s][A
Acc 26.77 Loss: 1.97:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:11<00:03, 11.75it/s][A
Acc 26.98 Loss: 1.97:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:12<00:03, 11.75it/s][A
Acc 27.13 Loss: 1.97:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:12<00:03, 11.75it/s][A
Acc 27.13 Loss: 1.97:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:12<00:03, 11.52it/s][A
Acc 27.23 Loss: 1.96:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:12<00:03, 11.52it/s][A
Acc 27.42 Loss: 1.96:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:12<00:03, 11.52it/s][A
Acc 27.42 Loss: 1.96:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:12<00:03, 11.35it/s][A
Acc 27.56 Loss: 1.96:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:12<00:03, 11.35it/s][A
Acc 27.66 Loss: 1.95:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:12<00:03, 11.35it/s][A
Acc 27.66 Loss: 1.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:12<00:02, 11.41it/s][A
Acc 27.82 Loss: 1.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:12<00:02, 11.41it/s][A
Acc 28.03 Loss: 1.94:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:12<00:02, 11.41it/s][A
Acc 28.03 Loss: 1.94:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:12<00:02, 11.37it/s][A
Acc 27.94 Loss: 1.94:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:12<00:02, 11.37it/s][A
Acc 28.13 Loss: 1.94:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:12<00:02, 11.37it/s][A
Acc 28.13 Loss: 1.94:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:12<00:02, 11.34it/s][A
Acc 28.35 Loss: 1.93:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:12<00:02, 11.34it/s][A
Acc 28.29 Loss: 1.93:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:13<00:02, 11.34it/s][A
Acc 28.29 Loss: 1.93:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:13<00:02, 11.37it/s][A
Acc 28.38 Loss: 1.93:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:13<00:02, 11.37it/s][A
Acc 28.51 Loss: 1.93:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:13<00:02, 11.37it/s][A
Acc 28.51 Loss: 1.93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:13<00:02, 11.34it/s][A
Acc 28.58 Loss: 1.92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:13<00:02, 11.34it/s][A
Acc 28.69 Loss: 1.92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:13<00:02, 11.34it/s][A
Acc 28.69 Loss: 1.92:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:13<00:02, 11.31it/s][A
Acc 28.68 Loss: 1.92:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:13<00:02, 11.31it/s][A
Acc 28.82 Loss: 1.92:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:13<00:02, 11.31it/s][A
Acc 28.82 Loss: 1.92:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:13<00:01, 11.52it/s][A
Acc 28.98 Loss: 1.92:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:13<00:01, 11.52it/s][A
Acc 28.99 Loss: 1.91:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:13<00:01, 11.52it/s][A
Acc 28.99 Loss: 1.91:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:13<00:01, 11.43it/s][A
Acc 29.17 Loss: 1.91:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:13<00:01, 11.43it/s][A
Acc 29.22 Loss: 1.91:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:13<00:01, 11.43it/s][A
Acc 29.22 Loss: 1.91:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:13<00:01, 11.43it/s][A
Acc 29.30 Loss: 1.91:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:14<00:01, 11.43it/s][A
Acc 29.42 Loss: 1.90:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:14<00:01, 11.43it/s][A
Acc 29.42 Loss: 1.90:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:14<00:01, 11.43it/s][Ax tensor(-0.1043, device='cuda:0')
out tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1269, device='cuda:0')
out tensor(0.3858, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1556, device='cuda:0')
out tensor(0.3891, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1318, device='cuda:0')
out tensor(0.3841, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.0930, device='cuda:0')
out tensor(0.3846, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1729, device='cuda:0')
out tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1508, device='cuda:0')
out tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1002, device='cuda:0')
out tensor(0.3817, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1272, device='cuda:0')
out tensor(0.3841, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1229, device='cuda:0')
out tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1559, device='cuda:0')
out tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1049, device='cuda:0')
out tensor(0.3843, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1218, device='cuda:0')
out tensor(0.3852, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1067, device='cuda:0')
out tensor(0.3825, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1290, device='cuda:0')
out tensor(0.3859, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1212, device='cuda:0')
out tensor(0.3865, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1460, device='cuda:0')
out tensor(0.3845, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1289, device='cuda:0')
out tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1533, device='cuda:0')
out tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1719, device='cuda:0')
out tensor(0.3862, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1583, device='cuda:0')
out tensor(0.3858, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1528, device='cuda:0')
out tensor(0.3874, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1351, device='cuda:0')
out tensor(0.3876, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1539, device='cuda:0')
out tensor(0.3866, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1565, device='cuda:0')
out tensor(0.3866, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1124, device='cuda:0')
out tensor(0.3828, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1679, device='cuda:0')
out tensor(0.3875, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1380, device='cuda:0')
out tensor(0.3889, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1325, device='cuda:0')
out tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1151, device='cuda:0')
out tensor(0.3812, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1197, device='cuda:0')
out tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1479, device='cuda:0')
out tensor(0.3815, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1245, device='cuda:0')
out tensor(0.3860, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1254, device='cuda:0')
out tensor(0.3849, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1249, device='cuda:0')
out tensor(0.3827, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1359, device='cuda:0')
out tensor(0.3853, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1620, device='cuda:0')
out tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1076, device='cuda:0')
out tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1604, device='cuda:0')
out tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1103, device='cuda:0')
out tensor(0.3843, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1304, device='cuda:0')
out tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1685, device='cuda:0')
out tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1433, device='cuda:0')
out tensor(0.3860, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1435, device='cuda:0')
out tensor(0.3868, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1399, device='cuda:0')
out tensor(0.3854, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1408, device='cuda:0')
out tensor(0.3864, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1201, device='cuda:0')
out tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1280, device='cuda:0')
out tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1093, device='cuda:0')
out tensor(0.3865, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1125, device='cuda:0')
out tensor(0.3837, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1497, device='cuda:0')
out tensor(0.3884, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1705, device='cuda:0')
out tensor(0.3877, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1631, device='cuda:0')
out tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1066, device='cuda:0')
out tensor(0.3826, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1412, device='cuda:0')
out tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1315, device='cuda:0')
out tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.0889, device='cuda:0')
out tensor(0.3821, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1057, device='cuda:0')
out tensor(0.3839, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1215, device='cuda:0')
out tensor(0.3875, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1387, device='cuda:0')
out tensor(0.3883, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1105, device='cuda:0')
out tensor(0.3843, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1364, device='cuda:0')
out tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1400, device='cuda:0')
out tensor(0.3848, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1425, device='cuda:0')
out tensor(0.3854, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1297, device='cuda:0')
out tensor(0.3841, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1469, device='cuda:0')
out tensor(0.3865, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1603, device='cuda:0')
out tensor(0.3868, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1283, device='cuda:0')
out tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1005, device='cuda:0')
out tensor(0.3808, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1318, device='cuda:0')
out tensor(0.3819, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1430, device='cuda:0')
out tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1116, device='cuda:0')
out tensor(0.3818, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1371, device='cuda:0')
out tensor(0.3820, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1632, device='cuda:0')
out tensor(0.3849, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1340, device='cuda:0')
out tensor(0.3833, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1152, device='cuda:0')
out tensor(0.3819, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1182, device='cuda:0')
out tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1123, device='cuda:0')
out tensor(0.3830, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1217, device='cuda:0')
out tensor(0.3846, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1621, device='cuda:0')
out tensor(0.3874, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1006, device='cuda:0')
out tensor(0.3784, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1319, device='cuda:0')
out tensor(0.3841, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1684, device='cuda:0')
out tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1423, device='cuda:0')
out tensor(0.3831, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1265, device='cuda:0')
out tensor(0.3801, device='cuda:0', grad_fn=<MeanBackward0>)
x 
Acc 29.53 Loss: 1.90:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:14<00:01, 11.43it/s][A
Acc 29.55 Loss: 1.90:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:14<00:01, 11.43it/s][A
Acc 29.55 Loss: 1.90:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:14<00:01, 11.39it/s][A
Acc 29.65 Loss: 1.90:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:14<00:01, 11.39it/s][A
Acc 29.63 Loss: 1.90:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:14<00:01, 11.39it/s][A
Acc 29.63 Loss: 1.90:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:14<00:00, 11.40it/s][A
Acc 29.61 Loss: 1.89:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:14<00:00, 11.40it/s][A
Acc 29.62 Loss: 1.89:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:14<00:00, 11.40it/s][A
Acc 29.62 Loss: 1.89:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:14<00:00, 11.40it/s][A
Acc 29.57 Loss: 1.89:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:14<00:00, 11.40it/s][A
Acc 29.63 Loss: 1.89:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:14<00:00, 11.40it/s][A
Acc 29.63 Loss: 1.89:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:14<00:00, 11.40it/s][A
Acc 29.61 Loss: 1.89:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:14<00:00, 11.40it/s][A
Acc 29.69 Loss: 1.89:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:14<00:00, 11.40it/s][A
Acc 29.69 Loss: 1.89:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:14<00:00, 11.41it/s][A
Acc 29.76 Loss: 1.88:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:15<00:00, 11.41it/s][A
Acc 29.89 Loss: 1.88:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:15<00:00, 11.41it/s][A
Acc 29.89 Loss: 1.88:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:15<00:00, 11.42it/s][A
Acc 29.88 Loss: 1.88:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:15<00:00, 11.42it/s][A
Acc 29.97 Loss: 1.88:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:15<00:00, 11.42it/s][A
Acc 29.97 Loss: 1.88:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:15<00:00, 11.42it/s][A
Acc 30.08 Loss: 1.87:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:15<00:00, 11.42it/s][AAcc 30.08 Loss: 1.87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:15<00:00,  6.47it/s]
  0%|          | 1/1000 [00:17<4:45:03, 17.12s/it]2023-06-26 23:33:00.868 | INFO     | __main__:train_poisoned_worker:606 - Training epoch #1 on poisoned client #0
2023-06-26 23:33:00.872 | INFO     | __main__:train:211 - Client 0 is poisoned
tensor(-0.1206, device='cuda:0')
out tensor(0.3845, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1494, device='cuda:0')
out tensor(0.3830, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1376, device='cuda:0')
out tensor(0.3857, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1324, device='cuda:0')
out tensor(0.3827, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1219, device='cuda:0')
out tensor(0.3778, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1259, device='cuda:0')
out tensor(0.3842, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1098, device='cuda:0')
out tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1295, device='cuda:0')
out tensor(0.3829, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1156, device='cuda:0')
out tensor(0.3794, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1425, device='cuda:0')
out tensor(0.3823, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1347, device='cuda:0')
out tensor(0.3871, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1319, device='cuda:0')
out tensor(0.3815, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1355, device='cuda:0')
out tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.1309, device='cuda:0')
out tensor(0.3790, device='cuda:0', grad_fn=<MeanBackward0>)
x tensor(-0.0930, device='cuda:0')
out tensor(0.3822, device='cuda:0', grad_fn=<MeanBackward0>)
Poisoned Client Training - loss:1.8749, accuracy:0.3008
./checkpoint/best_noise__client_0__target_label_2__exp_83.npy loaded
len(ori_train) 10000
random_poison_idx [2, 9, 10, 17, 19]
Traing dataset size is: 10000  Poison numbers is: 5

  0%|          | 0/100 [00:00<?, ?it/s][AERROR: Unexpected segmentation fault encountered in worker.
   0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 1/1000 [00:18<5:13:52, 18.85s/it]
DEBUG flwr 2023-06-26 23:33:02,681 | connection.py:113 | gRPC channel closed
Traceback (most recent call last):
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1136747) is killed by signal: Segmentation fault. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/Son/Clean-Label-FL-2-clients/client.py", line 964, in <module>
    fl.client.start_numpy_client(server_address="{}:{}".format(args.args_dict.fl_training.server_address, args.args_dict.fl_training.server_port), client=client)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/app.py", line 252, in start_numpy_client
    start_client(
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/app.py", line 178, in start_client
    client_message, sleep_duration, keep_going = handle(
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py", line 67, in handle
    return _fit(client, server_msg.fit_ins), 0, True
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py", line 126, in _fit
    fit_res = maybe_call_fit(
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/mnt/Son/Clean-Label-FL-2-clients/client.py", line 105, in fit
    results = self.train()
  File "/mnt/Son/Clean-Label-FL-2-clients/client.py", line 264, in train
    for images, labels in pbar: # loop through each batch
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1295, in _get_data
    success, data = self._try_get_data()
  File "/home/sonnh/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1146, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 1136747) exited unexpectedly
